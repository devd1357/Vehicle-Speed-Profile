{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BESTPOS ASCII TO CSV CONVERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been parsed and saved to /Users/ravitejakunchanapalli/Downloads/csvdata/bestposdata.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pytz\n",
    "import csv\n",
    "\n",
    "# Number of leap seconds to subtract from GPS time (18 seconds as of current)\n",
    "LEAP_SECONDS = 18\n",
    "\n",
    "# GPS epoch start date\n",
    "GPS_EPOCH = datetime.datetime(1980, 1, 6, tzinfo=datetime.timezone.utc)\n",
    "\n",
    "# IST timezone\n",
    "IST = pytz.timezone('Asia/Kolkata')\n",
    "\n",
    "def gps_to_ist(gps_week, tow):\n",
    "    \"\"\"\n",
    "    Convert GPS week and time of week to IST.\n",
    "    \"\"\"\n",
    "    # Total seconds since GPS epoch\n",
    "    total_seconds = gps_week * 7 * 24 * 3600 + tow - LEAP_SECONDS\n",
    "    # Convert to UTC\n",
    "    utc_time = GPS_EPOCH + datetime.timedelta(seconds=total_seconds)\n",
    "    # Convert to IST\n",
    "    ist_time = utc_time.astimezone(IST)\n",
    "    return ist_time\n",
    "\n",
    "# File paths\n",
    "input_file_path = \"/Users/ravitejakunchanapalli/Desktop/testing_data/BESTPOS.ASCII\"\n",
    "output_file_path = \"/Users/ravitejakunchanapalli/Downloads/csvdata/bestposdata.csv\"\n",
    "\n",
    "# Ensure the output directory exists\n",
    "output_directory = os.path.dirname(output_file_path)\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Initialize lists to store parsed data\n",
    "latitudes = []\n",
    "longitudes = []\n",
    "ist_times = []\n",
    "\n",
    "# Read the ASCII file and extract relevant fields\n",
    "with open(input_file_path, 'r') as file:\n",
    "    data = file.readlines()\n",
    "\n",
    "# Iterate through each line in the file\n",
    "for line in data:\n",
    "    # Split the line into log header and fields\n",
    "    log_header, fields = line.split(';')\n",
    "    log_header = log_header.split(',')\n",
    "    week = int(log_header[5])  # Assuming GPS week is at index 5\n",
    "    tow = float(log_header[6])  # Assuming time of week is at index 6\n",
    "    \n",
    "    # Split the fields into individual data points\n",
    "    fields = fields.split(',')\n",
    "\n",
    "    # Extracting relevant data (latitude, longitude, and height)\n",
    "    lat = float(fields[2])\n",
    "    lon = float(fields[3])\n",
    "\n",
    "    # Convert GPS week and time of week to IST time\n",
    "    ist_time = gps_to_ist(week, tow).strftime('%Y/%m/%d/%H:%M:%S.%f')  # Format to string\n",
    "\n",
    "    # Store the parsed data in lists\n",
    "    latitudes.append(lat)\n",
    "    longitudes.append(lon)\n",
    "    ist_times.append(ist_time)\n",
    "\n",
    "# Write the parsed data to a new CSV file\n",
    "with open(output_file_path, 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    # Write header\n",
    "    csvwriter.writerow(['time', 'latitude', 'longitude'])\n",
    "    # Write data\n",
    "    for ist_time, lat, lon in zip(ist_times, latitudes, longitudes):\n",
    "        csvwriter.writerow([ist_time, lat, lon])\n",
    "\n",
    "print(f\"Data has been parsed and saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BESTVEL ASCII TO CSV CONVERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been parsed and saved to /Users/ravitejakunchanapalli/Downloads/csvdata/bestveldata.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pytz\n",
    "import pandas as pd\n",
    "\n",
    "# Number of leap seconds to subtract from GPS time (18 seconds as of current)\n",
    "LEAP_SECONDS = 18\n",
    "\n",
    "# GPS epoch start date\n",
    "GPS_EPOCH = datetime.datetime(1980, 1, 6, tzinfo=datetime.timezone.utc)\n",
    "\n",
    "# IST timezone\n",
    "IST = pytz.timezone('Asia/Kolkata')\n",
    "\n",
    "def gps_to_ist(gps_week, tow):\n",
    "    \"\"\"\n",
    "    Convert GPS week and time of week to IST.\n",
    "    \"\"\"\n",
    "    # Total seconds since GPS epoch\n",
    "    total_seconds = gps_week * 7 * 24 * 3600 + tow - LEAP_SECONDS\n",
    "    # Convert to UTC\n",
    "    utc_time = GPS_EPOCH + datetime.timedelta(seconds=total_seconds)\n",
    "    # Convert to IST\n",
    "    ist_time = utc_time.astimezone(IST)\n",
    "    return ist_time\n",
    "\n",
    "def parse_bestvel_data(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith('#BESTVELA'):\n",
    "                log_header, fields = line.split(';')\n",
    "                log_header = log_header.split(',')\n",
    "                week = int(log_header[5])  # Assuming GPS week is at index 5\n",
    "                tow = float(log_header[6])  # Assuming time of week is at index 6\n",
    "                \n",
    "                fields = fields.split(',')\n",
    "                hor_speed = float(fields[4]) * 3.6  # Assuming hor_speed is at index 4 and convert to km/h\n",
    "               \n",
    "\n",
    "                # Convert GPS week and time of week to IST time\n",
    "                ist_time = gps_to_ist(week, tow).strftime('%Y/%m/%d/%H:%M:%S.%f')  # Format to string\n",
    "                \n",
    "                # Append the data to the list\n",
    "                data.append([ist_time, hor_speed])\n",
    "\n",
    "    return pd.DataFrame(data, columns=['time', 'horizontal_speed'])\n",
    "\n",
    "# File paths\n",
    "input_file_path = \"/Users/ravitejakunchanapalli/Desktop/testing_data/BESTVEL.ASCII\"\n",
    "output_file_path = \"/Users/ravitejakunchanapalli/Downloads/csvdata/bestveldata.csv\"\n",
    "\n",
    "# Ensure the output directory exists\n",
    "output_directory = os.path.dirname(output_file_path)\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Parse the bestvel data\n",
    "df = parse_bestvel_data(input_file_path)\n",
    "\n",
    "# Save the data to a CSV file\n",
    "df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Data has been parsed and saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images Fitting code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "import os\n",
    "from matplotlib import cm, colors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the GNSS data\n",
    "gnss_file_path = '/Users/ravitejakunchanapalli/Downloads/baleno_data/gnss_data.csv'\n",
    "gnss_df = pd.read_csv(gnss_file_path)\n",
    "gnss_df['time'] = pd.to_datetime(gnss_df['time'])\n",
    "\n",
    "# Load the BestVel data\n",
    "bestvel_file_path = '/Users/ravitejakunchanapalli/Downloads/baleno_data/bestvel_data.csv'\n",
    "bestvel_df = pd.read_csv(bestvel_file_path)\n",
    "bestvel_df['time'] = pd.to_datetime(bestvel_df['time'])\n",
    "\n",
    "# Load the Basler data\n",
    "basler_file_path = '/Users/ravitejakunchanapalli/Downloads/baleno_data/basler_data.csv'\n",
    "basler_df = pd.read_csv(basler_file_path)\n",
    "basler_df['time'] = pd.to_datetime(basler_df['time'])\n",
    "\n",
    "# Merge Basler data with GNSS data based on nearest timestamp from GNSS data\n",
    "merged_data = pd.merge_asof(gnss_df, basler_df, on='time')\n",
    "\n",
    "# Merge with BestVel data based on nearest timestamp from BestVel data\n",
    "merged_data = pd.merge_asof(bestvel_df, merged_data, on='time')\n",
    "\n",
    "# Directory containing images\n",
    "image_dir = '/Users/ravitejakunchanapalli/Downloads/baleno_images'\n",
    "\n",
    "# Function to get image filename based on time\n",
    "def get_nearest_image(time):\n",
    "    image_timestamps = pd.to_datetime(os.listdir(image_dir), format='image_%Y-%m-%d-%H-%M-%S.%f.jpg')\n",
    "    nearest_image = min(image_timestamps, key=lambda x: abs(x - time))\n",
    "    return f'image_{nearest_image.strftime(\"%Y-%m-%d-%H-%M-%S.%f\")}.jpg'\n",
    "\n",
    "# Attach nearest image filename to merged data\n",
    "merged_data['image_filename'] = merged_data['time'].apply(get_nearest_image)\n",
    "\n",
    "print(\"len\",len(merged_data))\n",
    "print(merged_data.head())\n",
    "# Normalize speed data for color mapping\n",
    "norm = colors.Normalize(vmin=merged_data['horizontal_speed'].min(), vmax=merged_data['horizontal_speed'].max())\n",
    "cmap = plt.get_cmap('RdYlGn_r')\n",
    "\n",
    "# Create the map\n",
    "m = folium.Map(\n",
    "    location=[merged_data['latitude'].mean(), merged_data['longitude'].mean()],\n",
    "    zoom_start=18,\n",
    "    tiles='https://mt1.google.com/vt/lyrs=s&x={x}&y={y}&z={z}',\n",
    "    attr='Google'\n",
    ")\n",
    "\n",
    "# Add points to the map with color-coded markers and popups based on speed\n",
    "for _, row in merged_data.iterrows():\n",
    "    color = colors.rgb2hex(cmap(norm(row['horizontal_speed'])))\n",
    "    popup_text = f\"Latitude: {row['latitude']:.6f}<br>Longitude: {row['longitude']:.6f}<br>Speed: {row['horizontal_speed']:.2f}\"\n",
    "    image_path = os.path.join(image_dir, row['image_filename'])\n",
    "    if os.path.exists(image_path):\n",
    "        folium.CircleMarker(\n",
    "            location=[row['latitude'], row['longitude']],\n",
    "            radius=3,\n",
    "            color=color,\n",
    "            fill=True,\n",
    "            fill_color=color,\n",
    "            fill_opacity=0.7,\n",
    "            popup=folium.Popup(popup_text + f\"<br><img src='{image_path}' width='200'>\", max_width=300)\n",
    "        ).add_to(m)\n",
    "    else:\n",
    "        folium.CircleMarker(\n",
    "            location=[row['latitude'], row['longitude']],\n",
    "            radius=3,\n",
    "            color=color,\n",
    "            fill=True,\n",
    "            fill_color=color,\n",
    "            fill_opacity=0.7,\n",
    "            popup=folium.Popup(popup_text, max_width=200)\n",
    "        ).add_to(m)\n",
    "\n",
    "# Save the map as an HTML file\n",
    "map_path = '/Users/ravitejakunchanapalli/Desktop/img_test6.html'\n",
    "m.save(map_path)\n",
    "print(f'Map saved to {map_path}')\n",
    "# Create a color bar and save as an image\n",
    "fig, ax = plt.subplots(figsize=(6, 1))\n",
    "fig.subplots_adjust(bottom=0.5)\n",
    "\n",
    "cbar = fig.colorbar(cm.ScalarMappable(norm=norm, cmap=cmap), cax=ax, orientation='horizontal')\n",
    "cbar.set_label('Speed (km/h)')\n",
    "\n",
    "colorbar_path = '/Users/ravitejakunchanapalli/Desktop/colorbar6.png'\n",
    "plt.savefig(colorbar_path)\n",
    "print(f'Color bar saved to {colorbar_path}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
